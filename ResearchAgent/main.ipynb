{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singapore Attraction Discovery Agent\n",
    "Agentic system for discovering Singapore attractions using tool-based reasoning, LLM decision-making, and iterative refinement to meet user requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install requirements if needed\n",
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "import math\n",
    "from typing import Dict, List, Any, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(os.path.join(os.path.dirname('.'), 'src'))\n",
    "\n",
    "try:\n",
    "    from openai import OpenAI\n",
    "except ImportError:\n",
    "    OpenAI = None\n",
    "\n",
    "try:\n",
    "    from anthropic import Anthropic\n",
    "except ImportError:\n",
    "    Anthropic = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.StreamHandler(),\n",
    "        logging.FileHandler('agent_reasoning.log', mode='a')\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Keys Status:\n",
      "GOOGLE_MAPS_API_KEY: ✓ Set\n",
      "CLIMATIQ_API_KEY: ✓ Set\n",
      "OPENAI_API_KEY: ✓ Set\n",
      "ANTHROPIC_API_KEY: ✗ Missing\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Check API keys\n",
    "print(\"API Keys Status:\")\n",
    "print(f\"GOOGLE_MAPS_API_KEY: {'✓ Set' if os.getenv('GOOGLE_MAPS_API_KEY') else '✗ Missing'}\")\n",
    "print(f\"CLIMATIQ_API_KEY: {'✓ Set' if os.getenv('CLIMATIQ_API_KEY') else '✗ Missing'}\")\n",
    "print(f\"OPENAI_API_KEY: {'✓ Set' if os.getenv('OPENAI_API_KEY') else '✗ Missing'}\")\n",
    "print(f\"ANTHROPIC_API_KEY: {'✓ Set' if os.getenv('ANTHROPIC_API_KEY') else '✗ Missing'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Data Loading\n",
    "Load and validate input file with trip requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available input files:\n",
      "  inputs/adventure_input.json\n",
      "  inputs/complex_input.json\n",
      "  inputs/family_budget_input.json\n",
      "  inputs/garden_only_input.json\n",
      "  inputs/simple_input.json\n"
     ]
    }
   ],
   "source": [
    "def load_input_file(file_path: str) -> dict:\n",
    "    \"\"\"Load and validate input file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as f:\n",
    "            input_data = json.load(f)\n",
    "        \n",
    "        # Basic validation\n",
    "        required_fields = [\"trip_dates\", \"duration_days\", \"budget\", \"pace\"]\n",
    "        for field in required_fields:\n",
    "            if field not in input_data:\n",
    "                raise ValueError(f\"Missing required field: {field}\")\n",
    "        \n",
    "        # Check if optional section exists, and validate accommodation_location if it does\n",
    "        if \"optional\" in input_data and \"accommodation_location\" not in input_data[\"optional\"]:\n",
    "            raise ValueError(\"Missing required field: optional.accommodation_location\")\n",
    "        \n",
    "        return input_data\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Input file '{file_path}' not found.\")\n",
    "        return None\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error: Invalid JSON in input file: {e}\")\n",
    "        return None\n",
    "    except ValueError as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Test with different input files\n",
    "print(\"Available input files:\")\n",
    "for file in os.listdir('../inputs'):\n",
    "    if file.endswith('.json'):\n",
    "        print(f\"  inputs/{file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Places Research Agent - Reasoning Implementation\n",
    "- Handles pure reasoning and analytical thinking\n",
    "- Executes API calls through tools (search_places, search_multiple_keywords, get_place_details)\n",
    "- Returns raw data objects from API calls without any formatting\n",
    "- Has the calculate_required_places method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import search_places, search_multiple_keywords, get_place_details\n",
    "\n",
    "class PlacesResearchReasoningAgent:\n",
    "    \"\"\"\n",
    "    Specialized agent for reasoning about location-based attraction research.\n",
    "    Returns raw data from Google Places API without formatting.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, system_prompt=\"\"):\n",
    "        # Initialize OpenAI client\n",
    "        self.client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        \n",
    "        # Agent configuration\n",
    "        self.model_name = \"gpt-4o\"\n",
    "        self.temperature = 0.3\n",
    "        \n",
    "        # Message history\n",
    "        self.messages = []\n",
    "        self.system_prompt = system_prompt or self._get_default_system_prompt()\n",
    "        \n",
    "        if self.system_prompt:\n",
    "            self.messages.append({\"role\": \"system\", \"content\": self.system_prompt})\n",
    "        \n",
    "        # Tool definitions for Google Places API\n",
    "        self.available_tools = self._define_places_tools()\n",
    "        \n",
    "        # Known actions mapping\n",
    "        self.known_actions = {\n",
    "            \"search_places\": search_places,\n",
    "            \"search_multiple_keywords\": search_multiple_keywords,\n",
    "            \"get_place_details\": get_place_details\n",
    "        }\n",
    "\n",
    "        # Agent state for tracking requirements\n",
    "        self.required_places = 0\n",
    "        self.current_results_count = 0\n",
    "    \n",
    "    def _get_default_system_prompt(self) -> str:\n",
    "        \"\"\"Default system prompt following thought-action-observation pattern.\"\"\"\n",
    "        return \"\"\"\n",
    "            You are a places and attractions research specialist. You run in a loop of Thought, Action, Observation.\n",
    "            At the end of the loop you output raw data results.\n",
    "            \n",
    "            Use Thought to describe your reasoning about the places and attractions research.\n",
    "            Use Action to run one of the actions available to you.\n",
    "            Observation will be the result of running those actions.\n",
    "            \n",
    "            INTEREST MAPPING RULES:\n",
    "            Before processing any interests, map them to the following standardized categories:\n",
    "            - tourist_attraction\n",
    "            - food\n",
    "            - cafe\n",
    "            - bar\n",
    "            - bakery\n",
    "            - park\n",
    "            - museum\n",
    "            - shopping_mall\n",
    "            - lodging\n",
    "            \n",
    "            Mapping examples:\n",
    "            - \"parks\" to park\n",
    "            - \"museums\" to museum\n",
    "            - \"family\" to tourist_attraction\n",
    "            - \"educational\" to museum or tourist_attraction\n",
    "            - \"gardens\" to park\n",
    "            - \"nature\" to park\n",
    "            - \"culture\" to museum or 'cultural food'\n",
    "            - \"dining\" to food\n",
    "            - \"coffee\" to cafe\n",
    "            - \"shopping\" to shopping_mall\n",
    "            - \"accommodation\" to lodging\n",
    "            \n",
    "            Special handling for food-related interests:\n",
    "            If an interest cannot be classified into the above categories but refers to food options \n",
    "            (like \"vegetarian\", \"halal\", \"vegan\", \"local cuisine\"), rewrite it as \"[interest] food\".\n",
    "            Examples:\n",
    "            - \"vegetarian\" → \"vegetarian food\"\n",
    "            - \"halal\" → \"halal food\"\n",
    "            - \"local cuisine\" → \"local food\"\n",
    "            \n",
    "            Your available actions are:\n",
    "            1. search_places when there is only ONE interest/keyword to search for.\n",
    "            2. search_multiple_keywords when there are MULTIPLE interests/keywords to search for.\n",
    "            3. get_place_details to get comprehensive details about all places.\n",
    "            \n",
    "            The 'interests' input from user maps to:\n",
    "            - 'keyword' parameter for search_places (single string)\n",
    "            - 'keywords' parameter for search_multiple_keywords (array of strings)\n",
    "\n",
    "            Finds attractions near accomodation location and find at least one food places per day.\n",
    "            \n",
    "            Set ratings filter to a 3.5 for shopping malls.\n",
    "            Set ratings filter to a 4.2 for food places.\n",
    "            Set ratings filter to a 4.0 for all other place types.\n",
    "            \n",
    "            Return raw data objects from API calls. Do not format the output.\n",
    "            Focus on comprehensive data collection based on user interests and accommodation location.\n",
    "            Always consider practical factors like location, ratings, accessibility needs, and user preferences.\n",
    "            Calculate required places based on pace and duration, and expand search if insufficient results are found.\n",
    "            \"\"\".strip()\n",
    "\n",
    "    def _define_places_tools(self) -> List[Dict]:\n",
    "        \"\"\"Define Google Places API tools.\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"search_places\",\n",
    "                    \"description\": \"Search for places with a SINGLE keyword/interest based on user interests and accommodation location\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"location\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"lat\": {\"type\": \"number\", \"description\": \"Latitude of accommodation\"},\n",
    "                                    \"lng\": {\"type\": \"number\", \"description\": \"Longitude of accommodation\"},\n",
    "                                    # \"neighborhood\": {\"type\": \"string\", \"description\": \"Neighborhood name (optional)\"}\n",
    "                                },\n",
    "                                \"required\": [\"lat\", \"lng\"],\n",
    "                                \"description\": \"Accommodation location with coordinates\"\n",
    "                            },\n",
    "                            \"keyword\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"A single user interest like 'tourist_attraction'\"\n",
    "                            },\n",
    "                            \"radius\": {\n",
    "                                \"type\": \"integer\",\n",
    "                                \"description\": \"Search radius in meters (default: 5000, increase by 2000 if not enough results)\",\n",
    "                                \"default\": 5000\n",
    "                            },\n",
    "                            \"max_pages\": {\n",
    "                                \"type\": \"integer\",\n",
    "                                \"description\": \"Maximum number of pages to retrieve (default: 3), Each page has up to 20 results.\",\n",
    "                                \"default\": 1\n",
    "                            },\n",
    "                            \"min_rating\": {\n",
    "                                \"type\": \"number\",\n",
    "                                \"description\": \"Minimum rating filter (1.0-5.0)\",\n",
    "                                \"default\": 4.0\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"location\", \"keyword\"]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"search_multiple_keywords\",\n",
    "                    \"description\": \"Search for places with MULTIPLE keywords/interests based on user interests and accommodation location\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"location\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"lat\": {\"type\": \"number\", \"description\": \"Latitude of accommodation\"},\n",
    "                                    \"lng\": {\"type\": \"number\", \"description\": \"Longitude of accommodation\"},\n",
    "                                    # \"neighborhood\": {\"type\": \"string\", \"description\": \"Neighborhood name (optional)\"}\n",
    "                                },\n",
    "                                \"required\": [\"lat\", \"lng\"],\n",
    "                                \"description\": \"Accommodation location with coordinates\"\n",
    "                            },\n",
    "                            \"keywords\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"items\": {\"type\": \"string\"},\n",
    "                                \"description\": \"Array of user interests\"\n",
    "                            },\n",
    "                            \"radius\": {\n",
    "                                \"type\": \"integer\",\n",
    "                                \"description\": \"Search radius in meters (default: 5000, increases if not enough results)\",\n",
    "                                \"default\": 5000\n",
    "                            },\n",
    "                            \"max_pages\": {\n",
    "                                \"type\": \"integer\",\n",
    "                                \"description\": \"Maximum number of pages to retrieve (default: 1), Each page has up to 20 results.\",\n",
    "                                \"default\": 1\n",
    "                            },\n",
    "                            \"min_rating\": {\n",
    "                                \"type\": \"number\",\n",
    "                                \"description\": \"Minimum rating filter (1.0-5.0)\",\n",
    "                                \"default\": 4.0\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"location\", \"keywords\"]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"get_place_details\",\n",
    "                    \"description\": \"Get comprehensive detailed information about on a list of places\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"place_ids\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"items\": {\"type\": \"string\"},\n",
    "                                \"description\": \"Google Places API place_ids\"\n",
    "                            },\n",
    "                            \"fields\": {\n",
    "                                \"type\": \"array\",\n",
    "                                \"items\": {\"type\": \"string\"},\n",
    "                                \"description\": \"Specific fields to retrieve\",\n",
    "                                \"default\": [\"name\", \"formatted_address\", \"geometry\", \"opening_hours\", \"rating\", \"website\", \"price_level\", \"type\"]\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"place_ids\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    def __call__(self, message: str) -> Dict:\n",
    "        \"\"\"Execute reasoning and return raw data.\"\"\"\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": str(result)})\n",
    "        return result\n",
    "    \n",
    "    def execute(self) -> Dict:\n",
    "        \"\"\"Execute with function calling support, return raw data.\"\"\"\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            temperature=self.temperature,\n",
    "            messages=self.messages,\n",
    "            tools=self.available_tools,\n",
    "            tool_choice=\"auto\"\n",
    "        )\n",
    "        \n",
    "        message = response.choices[0].message\n",
    "        \n",
    "        # Handle function calls if present\n",
    "        if message.tool_calls:\n",
    "            # Add assistant message with tool calls\n",
    "            self.messages.append({\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": message.content,\n",
    "                \"tool_calls\": message.tool_calls\n",
    "            })\n",
    "            \n",
    "            all_tool_results = []\n",
    "            \n",
    "            # Execute tool calls\n",
    "            for tool_call in message.tool_calls:\n",
    "                tool_result = self._execute_tool_call(tool_call)\n",
    "                all_tool_results.append({\n",
    "                    \"tool\": tool_call.function.name,\n",
    "                    \"args\": json.loads(tool_call.function.arguments),\n",
    "                    \"result\": tool_result\n",
    "                })\n",
    "                \n",
    "                # Add tool result to messages\n",
    "                self.messages.append({\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"content\": json.dumps(tool_result, default=str)\n",
    "                })\n",
    "            \n",
    "            # Return raw data from tools\n",
    "            return {\n",
    "                \"reasoning\": message.content,\n",
    "                \"tool_results\": all_tool_results,\n",
    "                \"raw_places\": self._extract_places_from_results(all_tool_results)\n",
    "            }\n",
    "        \n",
    "        return {\n",
    "            \"reasoning\": message.content,\n",
    "            \"tool_results\": [],\n",
    "            \"raw_places\": []\n",
    "        }\n",
    "    \n",
    "    def _execute_tool_call(self, tool_call) -> Dict[str, Any]:\n",
    "        \"\"\"Execute tool call and return raw results.\"\"\"\n",
    "        tool_name = tool_call.function.name\n",
    "        tool_args = json.loads(tool_call.function.arguments)\n",
    "        \n",
    "        print(f\"REASONING AGENT: Executing {tool_name} with args: {tool_args}\")\n",
    "        \n",
    "        if tool_name in self.known_actions:\n",
    "            return self.known_actions[tool_name](**tool_args)\n",
    "        else:\n",
    "            return {\"error\": f\"Unknown tool: {tool_name}\"}\n",
    "    \n",
    "    def _extract_places_from_results(self, tool_results: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"Extract all place data from tool results.\"\"\"\n",
    "        all_places = []\n",
    "        for result in tool_results:\n",
    "            if result[\"tool\"] in [\"search_places\", \"search_multiple_keywords\"]:\n",
    "                places = result.get(\"result\", [])\n",
    "                if isinstance(places, list):\n",
    "                    all_places.extend(places)\n",
    "        return all_places\n",
    "\n",
    "    def calculate_required_places(self, pace: str, duration_days: int) -> int:\n",
    "        \"\"\"\n",
    "        Agent's internal goal-setting: Calculate required number of places.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            pace_mapping = {\n",
    "                \"slow\": 2,\n",
    "                \"relaxed\": 4,\n",
    "                \"moderate\": 4,\n",
    "                \"active\": 6,\n",
    "                \"standard\": 6,\n",
    "                \"fast\": 8,\n",
    "                \"intensive\": 8\n",
    "            }\n",
    "            \n",
    "            multiplier = float(os.getenv(\"MAX_PLACES_MULTIPLIER\", \"2\"))\n",
    "            pace_value = pace_mapping.get(pace.lower(), 6)\n",
    "            required_places = int(pace_value * duration_days * multiplier)\n",
    "            \n",
    "            # Only enforce minimum, no maximum cap\n",
    "            required_places = max(required_places, 15)  # Minimum 15 places\n",
    "\n",
    "            print(f\"REASONING AGENT: Goal set - {required_places} places for {pace} pace over {duration_days} days\")\n",
    "            return required_places\n",
    "            \n",
    "        except (ValueError, TypeError, AttributeError):\n",
    "            print(\"REASONING AGENT: Failed to calculate required places, using default: 15\")\n",
    "            return 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Places Research Agent - Formatting Implementation\n",
    "- Takes raw Google Places API data as input\n",
    "- Transforms it into specified schema format required by the planning agent\n",
    "- Sets null values for unavailable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import search_wikipedia\n",
    "\n",
    "class PlacesResearchFormattingAgent:\n",
    "    \"\"\"\n",
    "    Specialized agent for formatting raw Google Places API data into structured output.\n",
    "    Handles data from both search_places/search_multiple_keywords and get_place_details.\n",
    "    Includes Wikipedia integration.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, use_llm_for_all: bool = False):\n",
    "        # Initialize OpenAI client for complex formatting\n",
    "        self.client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "        self.model_name = \"gpt-4o\"\n",
    "        self.temperature = 0.1  # Lower temperature for consistent formatting\n",
    "        self.use_llm_for_all = use_llm_for_all  # Option to use LLM for entire transformation\n",
    "        \n",
    "        # Known actions mapping\n",
    "        self.known_actions = {\n",
    "            \"search_wikipedia\": search_wikipedia\n",
    "        }\n",
    "        \n",
    "    def _define_tools(self) -> List[Dict]:\n",
    "        \"\"\"Define available tools for the agent.\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"search_wikipedia\",\n",
    "                    \"description\": \"Search Wikipedia for information about a place.\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"search_term\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The name of the place to search for.\"\n",
    "                            }\n",
    "                        },\n",
    "                        \"required\": [\"search_term\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    def format_response(self, reasoning_data: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Format the complete response from reasoning agent.\n",
    "        \n",
    "        Args:\n",
    "            reasoning_data: Raw data from reasoning agent containing:\n",
    "                - reasoning: The thought process\n",
    "                - tool_results: List of tool execution results\n",
    "                - raw_places: Extracted places from tool results\n",
    "        \n",
    "        Returns:\n",
    "            Formatted response with structured place data\n",
    "        \"\"\"\n",
    "        # Extract raw places from the reasoning data\n",
    "        raw_places = reasoning_data.get('raw_places', [])\n",
    "        \n",
    "        # If raw_places is empty, try extracting from tool_results\n",
    "        if not raw_places:\n",
    "            tool_results = reasoning_data.get('tool_results', [])\n",
    "            for tool_result in tool_results:\n",
    "                if tool_result.get('tool') in ['search_places', 'search_multiple_keywords']:\n",
    "                    result = tool_result.get('result', [])\n",
    "                    if isinstance(result, list):\n",
    "                        raw_places.extend(result)\n",
    "        \n",
    "        logger.info(f\"Processing {len(raw_places)} raw places for formatting\")\n",
    "        \n",
    "        # Format the places using the existing format_places method\n",
    "        formatted_places = self.format_places(raw_places, {})\n",
    "        \n",
    "        return {\n",
    "            \"reasoning\": reasoning_data.get('reasoning'),\n",
    "            \"places_found\": len(formatted_places),\n",
    "            \"formatted_places\": formatted_places\n",
    "        }\n",
    "    \n",
    "    def format_places(self, search_results: List[Dict] = None, details_results: Dict[str, Dict] = None) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Format raw Google Places API data into structured schema.\n",
    "        \n",
    "        Args:\n",
    "            search_results: List of raw place data from search_places/search_multiple_keywords\n",
    "            details_results: Dict of place_id -> details from get_place_details\n",
    "            \n",
    "        Returns:\n",
    "            List of formatted place dictionaries according to schema\n",
    "        \"\"\"\n",
    "        # Option 1: Use full LLM transformation (if enabled)\n",
    "        if self.use_llm_for_all:\n",
    "            return self._format_places_llm_only(search_results, details_results)\n",
    "        \n",
    "        # Option 2: Use hybrid approach (default - more efficient)\n",
    "        formatted_places = []\n",
    "        \n",
    "        # Process search results\n",
    "        if search_results:\n",
    "            for place in search_results:\n",
    "                place_id = place.get('place_id')\n",
    "                \n",
    "                # Get details if available\n",
    "                details = details_results.get(place_id, {}) if details_results else {}\n",
    "                \n",
    "                # Merge search and details data\n",
    "                formatted_place = self._format_single_place(place, details)\n",
    "                formatted_places.append(formatted_place)\n",
    "        \n",
    "        # If we only have details results (no search results)\n",
    "        elif details_results:\n",
    "            for place_id, details in details_results.items():\n",
    "                formatted_place = self._format_single_place({}, details)\n",
    "                formatted_place['place_id'] = place_id\n",
    "                formatted_places.append(formatted_place)\n",
    "        \n",
    "        # Generate descriptions and tags using Wikipedia\n",
    "        if formatted_places:\n",
    "            formatted_places = self._generate_wikipedia_descriptions(formatted_places)\n",
    "        \n",
    "        return formatted_places\n",
    "    \n",
    "    def _format_single_place(self, search_data: Dict, details_data: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Format a single place from raw API data to structured schema.\n",
    "        Combines data from both search and details API responses.\n",
    "        \"\"\"\n",
    "        # Extract place_id and name (prefer from search, fallback to details)\n",
    "        place_id = search_data.get('place_id') or details_data.get('place_id')\n",
    "        name = search_data.get('name') or details_data.get('name', 'Unknown Place')\n",
    "        \n",
    "        # Extract types and map to standard type\n",
    "        types = search_data.get('types', []) or details_data.get('types', [])\n",
    "        primary_type = self._map_to_standard_type(types[0] if types else None)\n",
    "        \n",
    "        # Extract geo coordinates\n",
    "        geo = self._extract_geo(search_data, details_data)\n",
    "        \n",
    "        # Calculate geo_cluster_id\n",
    "        geo_cluster_id = self._calculate_geo_cluster(geo)\n",
    "        \n",
    "        # Extract address (prefer details formatted_address, fallback to vicinity)\n",
    "        address = (details_data.get('formatted_address') or \n",
    "            search_data.get('vicinity') or \n",
    "            search_data.get('formatted_address'))\n",
    "        \n",
    "        # Extract rating (can be in either response)\n",
    "        rating = details_data.get('rating') or search_data.get('rating')\n",
    "        \n",
    "        # Extract cost from price_level if available\n",
    "        price_level = details_data.get('price_level') or search_data.get('price_level')\n",
    "        cost_sgd = self._map_price_level_to_cost(price_level)\n",
    "        \n",
    "        # Extract website from details\n",
    "        website = details_data.get('website')\n",
    "        \n",
    "        # Extract opening hours for LLM processing\n",
    "        opening_hours_raw = details_data.get('opening_hours', {})\n",
    "        \n",
    "        # Format the place according to schema\n",
    "        formatted_place = {\n",
    "            \"place_id\": place_id,\n",
    "            \"name\": name,\n",
    "            \"type\": primary_type,\n",
    "            \"cost_sgd\": cost_sgd,\n",
    "            \"onsite_co2_kg\": None,  # Ignored\n",
    "            \"geo\": geo,\n",
    "            \"geo_cluster_id\": geo_cluster_id,\n",
    "            \"address\": address,\n",
    "            \"nearest_mrt\": None,  # Ignored\n",
    "            \"opening_hours\": {\n",
    "                \"monday\": None,\n",
    "                \"tuesday\": None,\n",
    "                \"wednesday\": None,\n",
    "                \"thursday\": None,\n",
    "                \"friday\": None,\n",
    "                \"saturday\": None,\n",
    "                \"sunday\": None\n",
    "            },  # Will be formatted by LLM if data available\n",
    "            \"duration_recommended_minutes\": None,  # Ignored\n",
    "            \"ticket_price_sgd\": {\n",
    "                \"adult\": None,\n",
    "                \"child\": None,\n",
    "                \"senior\": None\n",
    "            },  # Ignored\n",
    "            \"vegetarian_friendly\": None,  # Ignored\n",
    "            \"low_carbon_score\": None,  # Ignored\n",
    "            \"description\": None,  # Will be set by Wikipedia search\n",
    "            \"links\": {\n",
    "                \"official\": website,\n",
    "                \"reviews\": None  # Ignored\n",
    "            },\n",
    "            \"rating\": rating,\n",
    "            \"tags\": [],  # Will be set by Wikipedia search\n",
    "            \"_raw_types\": types,  # Store for reference\n",
    "            \"_raw_opening_hours\": opening_hours_raw  # Store for reference\n",
    "        }\n",
    "        \n",
    "        return formatted_place\n",
    "    \n",
    "    def _calculate_geo_cluster(self, geo: Optional[Dict]) -> Optional[str]:\n",
    "        \"\"\"Calculate geo cluster ID from coordinates using Singapore geographic rules.\"\"\"\n",
    "        if not geo or not geo.get('latitude') or not geo.get('longitude'):\n",
    "            return None\n",
    "            \n",
    "        lat = geo['latitude']\n",
    "        lng = geo['longitude']\n",
    "        \n",
    "        # Singapore bounds check\n",
    "        if not (1.1 <= lat <= 1.5 and 103.6 <= lng <= 104.1):\n",
    "            return None\n",
    "        \n",
    "        # Cluster logic for Singapore\n",
    "        if 1.25 <= lat <= 1.35 and 103.7 <= lng <= 103.9:\n",
    "            return \"central\"\n",
    "        elif lat > 1.35:\n",
    "            return \"north\"\n",
    "        elif lat < 1.35:\n",
    "            return \"south\"\n",
    "        elif lng > 103.8:\n",
    "            return \"east\"\n",
    "        else:\n",
    "            return \"west\"\n",
    "    \n",
    "    def _generate_wikipedia_descriptions(self, places: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Generate descriptions and tags for places using Wikipedia search.\n",
    "        Process in batches for efficiency.\n",
    "        \"\"\"\n",
    "        if not places:\n",
    "            return places\n",
    "        \n",
    "        # Process in batches to avoid token limits\n",
    "        batch_size = 10\n",
    "        processed_places = []\n",
    "        \n",
    "        for i in range(0, len(places), batch_size):\n",
    "            batch = places[i:i + batch_size]\n",
    "            batch_num = i // batch_size + 1\n",
    "            \n",
    "            logger.info(f\"Processing Wikipedia batch {batch_num} with {len(batch)} places\")\n",
    "            \n",
    "            # Search Wikipedia for each place\n",
    "            wikipedia_results = {}\n",
    "            for place in batch:\n",
    "                try:\n",
    "                    wiki_result = search_wikipedia(search_term=place[\"name\"])\n",
    "                    wikipedia_results[place[\"name\"]] = wiki_result\n",
    "                    logger.info(f\"Found Wikipedia info for: {place['name']}\")\n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"No Wikipedia info for {place['name']}: {e}\")\n",
    "                    wikipedia_results[place[\"name\"]] = None\n",
    "            \n",
    "            # Use LLM to create descriptions and tags from Wikipedia results\n",
    "            try:\n",
    "                enriched_batch = self._create_descriptions_from_wikipedia(batch, wikipedia_results)\n",
    "                processed_places.extend(enriched_batch)\n",
    "                logger.info(f\"Successfully enriched batch {batch_num}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to create descriptions for batch {batch_num}: {e}\")\n",
    "                # Keep places without descriptions/tags\n",
    "                for place in batch:\n",
    "                    place.pop(\"_raw_types\", None)\n",
    "                    place.pop(\"_raw_opening_hours\", None)\n",
    "                processed_places.extend(batch)\n",
    "        \n",
    "        return processed_places\n",
    "    \n",
    "    def _create_descriptions_from_wikipedia(self, batch: List[Dict], wikipedia_results: Dict) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Use LLM to create descriptions and tags from Wikipedia search results.\n",
    "        \"\"\"\n",
    "        # Prepare data for LLM\n",
    "        places_with_wiki = []\n",
    "        for place in batch:\n",
    "            place_data = {\n",
    "                \"name\": place[\"name\"],\n",
    "                \"type\": place[\"type\"],\n",
    "                \"address\": place.get(\"address\"),\n",
    "                \"rating\": place.get(\"rating\"),\n",
    "                \"wikipedia_info\": wikipedia_results.get(place[\"name\"])\n",
    "            }\n",
    "            places_with_wiki.append(place_data)\n",
    "        \n",
    "        prompt = f\"\"\"You are a Singapore tourism expert. Create compelling descriptions and tags for these places based on their Wikipedia information.\n",
    "\n",
    "Places with Wikipedia data:\n",
    "{json.dumps(places_with_wiki, indent=2)}\n",
    "\n",
    "For each place:\n",
    "1. If Wikipedia info is available, use it to create an accurate, engaging 1-2 sentence description\n",
    "2. If no Wikipedia info, create a simple description based on the name and type\n",
    "3. Generate 3-5 relevant tags for travelers\n",
    "\n",
    "Return a JSON array (no markdown formatting) with the same order, each object containing:\n",
    "- description: 1-2 sentence compelling tourist description\n",
    "- tags: array of 3-5 relevant tags\n",
    "\n",
    "Example format:\n",
    "[{{\"description\": \"Iconic waterfront park featuring Singapore's famous Merlion statue\", \"tags\": [\"landmark\", \"waterfront\", \"photo spot\", \"free entry\", \"iconic\"]}}]\n",
    "\"\"\"\n",
    "\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a Singapore tourism expert. Create descriptions and tags based on Wikipedia information.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=self.temperature\n",
    "        )\n",
    "        \n",
    "        llm_output = response.choices[0].message.content.strip()\n",
    "        \n",
    "        # Handle markdown-wrapped JSON\n",
    "        llm_output = self._extract_json_from_markdown(llm_output)\n",
    "        \n",
    "        logger.info(f\"LLM response (first 100 chars): {llm_output[:100]}...\")\n",
    "        \n",
    "        llm_data = json.loads(llm_output)\n",
    "        \n",
    "        # Merge LLM data back into places\n",
    "        for i, place in enumerate(batch):\n",
    "            if i < len(llm_data):\n",
    "                llm_place = llm_data[i]\n",
    "                place[\"description\"] = llm_place.get(\"description\", \"A place to visit in Singapore\")\n",
    "                place[\"tags\"] = llm_place.get(\"tags\", [place[\"type\"]])\n",
    "            else:\n",
    "                place[\"description\"] = f\"A {place['type']} in Singapore\"\n",
    "                place[\"tags\"] = [place[\"type\"]]\n",
    "            \n",
    "            # Clean up temp fields\n",
    "            place.pop(\"_raw_types\", None)\n",
    "            place.pop(\"_raw_opening_hours\", None)\n",
    "        \n",
    "        return batch\n",
    "    \n",
    "    def _extract_json_from_markdown(self, text: str) -> str:\n",
    "        \"\"\"Extract JSON from markdown code blocks.\"\"\"\n",
    "        import re\n",
    "        \n",
    "        # Remove ```json and ``` markers\n",
    "        if '```json' in text:\n",
    "            pattern = r'```json\\s*(.*?)\\s*```'\n",
    "            match = re.search(pattern, text, re.DOTALL)\n",
    "            if match:\n",
    "                return match.group(1).strip()\n",
    "        \n",
    "        # Remove ``` markers without json\n",
    "        if text.startswith('```') and text.endswith('```'):\n",
    "            lines = text.split('\\n')\n",
    "            if lines[0] == '```' or lines[0].startswith('```'):\n",
    "                lines = lines[1:]\n",
    "            if lines[-1] == '```':\n",
    "                lines = lines[:-1]\n",
    "            return '\\n'.join(lines).strip()\n",
    "        \n",
    "        return text.strip()\n",
    "    \n",
    "    def _format_places_llm_only(self, \n",
    "                                search_results: List[Dict] = None,\n",
    "                                details_results: Dict[str, Dict] = None) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Use LLM for complete transformation (fallback method).\n",
    "        Less efficient but more flexible for handling unexpected data formats.\n",
    "        \"\"\"\n",
    "        # Combine all data\n",
    "        combined_data = []\n",
    "        \n",
    "        if search_results:\n",
    "            for place in search_results:\n",
    "                place_id = place.get('place_id')\n",
    "                if details_results and place_id in details_results:\n",
    "                    # Merge search and details\n",
    "                    merged = {**place, **details_results[place_id]}\n",
    "                    combined_data.append(merged)\n",
    "                else:\n",
    "                    combined_data.append(place)\n",
    "        elif details_results:\n",
    "            combined_data = list(details_results.values())\n",
    "        \n",
    "        if not combined_data:\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # Use LLM for complete transformation\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=self.model_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": self._get_full_transformation_prompt()},\n",
    "                    {\"role\": \"user\", \"content\": f\"Transform these places:\\n{json.dumps(combined_data, indent=2)}\"}\n",
    "                ],\n",
    "                temperature=self.temperature\n",
    "            )\n",
    "            \n",
    "            result_text = self._extract_json_from_markdown(response.choices[0].message.content)\n",
    "            result = json.loads(result_text)\n",
    "            return result if isinstance(result, list) else []\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in LLM transformation: {e}\")\n",
    "            # Fallback to hybrid approach\n",
    "            self.use_llm_for_all = False  # Prevent infinite recursion\n",
    "            result = self.format_places(search_results, details_results)\n",
    "            self.use_llm_for_all = True  # Restore original setting\n",
    "            return result\n",
    "    \n",
    "    def _extract_geo(self, search_data: Dict, details_data: Dict) -> Optional[Dict]:\n",
    "        \"\"\"Extract geo coordinates from either search or details data.\"\"\"\n",
    "        # Try search data first\n",
    "        if search_data.get('geometry'):\n",
    "            location = search_data['geometry'].get('location', {})\n",
    "            if location:\n",
    "                return {\n",
    "                    \"latitude\": location.get('lat'),\n",
    "                    \"longitude\": location.get('lng')\n",
    "                }\n",
    "        \n",
    "        # Try details data\n",
    "        if details_data.get('geometry'):\n",
    "            location = details_data['geometry'].get('location', {})\n",
    "            if location:\n",
    "                return {\n",
    "                    \"latitude\": location.get('lat'),\n",
    "                    \"longitude\": location.get('lng')\n",
    "                }\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _map_to_standard_type(self, google_type: str) -> str:\n",
    "        \"\"\"Map Google Places type to standard type.\"\"\"\n",
    "        if not google_type:\n",
    "            return \"attraction\"\n",
    "        \n",
    "        type_mapping = {\n",
    "            \"tourist_attraction\": \"attraction\",\n",
    "            \"point_of_interest\": \"attraction\",\n",
    "            \"establishment\": \"attraction\",\n",
    "            \"restaurant\": \"food\",\n",
    "            \"food\": \"food\",\n",
    "            \"cafe\": \"cafe\",\n",
    "            \"bar\": \"bar\",\n",
    "            \"bakery\": \"bakery\",\n",
    "            \"park\": \"park\",\n",
    "            \"museum\": \"museum\",\n",
    "            \"shopping_mall\": \"shopping\",\n",
    "            \"lodging\": \"accommodation\",\n",
    "            \"hotel\": \"accommodation\",\n",
    "            \"art_gallery\": \"museum\"\n",
    "        }\n",
    "        \n",
    "        return type_mapping.get(google_type.lower(), \"attraction\")\n",
    "    \n",
    "    def _map_price_level_to_cost(self, price_level: Optional[int]) -> Optional[int]:\n",
    "        \"\"\"Map Google's price level (0-4) to cost range.\"\"\"\n",
    "        if price_level is None:\n",
    "            return None\n",
    "        \n",
    "        price_mapping = {\n",
    "            0: 0,  # Free or $0-5\n",
    "            1: 1,  # $5-15\n",
    "            2: 2,  # $15-30\n",
    "            3: 3,  # $30-60\n",
    "            4: 4   # $60+\n",
    "        }\n",
    "        \n",
    "        return price_mapping.get(price_level, None)\n",
    "    \n",
    "    def _get_full_transformation_prompt(self) -> str:\n",
    "        \"\"\"\n",
    "        Full system prompt for complete LLM-based transformation.\n",
    "        \"\"\"\n",
    "        return \"\"\"\n",
    "            You are a data transformation assistant. Your task is to take a list of Google Places API JSON objects and convert each object into the following custom attraction format.\n",
    "            \n",
    "            - If a field from the custom format is not available in the input data, set it to Python's None. \n",
    "            - Use the \"types\" field from Google Places as \"tags\" in the output.\n",
    "            - Use the \"geometry.location.lat\" and \"geometry.location.lng\" fields for latitude and longitude.\n",
    "            - Use the \"formatted_address\" field for address, fallback to \"vicinity\" if not available.\n",
    "            - Map the primary type to standard types (restaurant/food→\"food\", park→\"park\", museum/art_gallery→\"museum\", hotel/lodging→\"accommodation\", else→\"attraction\").\n",
    "            - Opening hours should be formatted as \"HH:MM-HH:MM\" or \"Open 24 hours\" from weekday_text.\n",
    "            - Map price_level (0-4) to cost_sgd (0=free, 1=$5-15, 2=$15-30, 3=$30-60, 4=$60+).\n",
    "            - Generate engaging descriptions for tourists.\n",
    "            - Set geo_cluster_id based on coordinates (lat>1.35→north, lat<1.35→south, lng>103.8→east, lng<103.8→west, central if between).\n",
    "            \"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Places Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlacesClusteringAgent:\n",
    "    \"\"\"\n",
    "    Agent for clustering attractions geographically and thematically for optimal travel planning.\n",
    "    Groups places by geo_cluster_id and calculates travel connections with accommodation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.accommodation_location = None\n",
    "        self.cluster_mapping = {\n",
    "            \"central\": {\"name\": \"Central Singapore\"},\n",
    "            \"north\": {\"name\": \"Northern Singapore\"},\n",
    "            \"south\": {\"name\": \"Southern Singapore\"},\n",
    "            \"east\": {\"name\": \"Eastern Singapore\"},\n",
    "            \"west\": {\"name\": \"Western Singapore\"}\n",
    "        }\n",
    "\n",
    "    def cluster_places(self, places_data: Dict, accommodation_location: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Cluster places geographically and add travel connections.\n",
    "\n",
    "        Args:\n",
    "            places_data: Formatted places data from PlacesResearchFormattingAgent\n",
    "            accommodation_location: Dict with lat, lng of accommodation\n",
    "\n",
    "        Returns:\n",
    "            Clustered data with travel connections and modes\n",
    "        \"\"\"\n",
    "        self.accommodation_location = accommodation_location\n",
    "        places = places_data.get('formatted_places', [])\n",
    "\n",
    "        if not places:\n",
    "            return self._create_empty_clusters_response(places_data)\n",
    "\n",
    "        # Group places by geo_cluster_id\n",
    "        clusters = self._group_by_geo_cluster(places)\n",
    "\n",
    "        # Calculate travel connections for each cluster\n",
    "        clustered_results = []\n",
    "        for cluster_id, cluster_places in clusters.items():\n",
    "            cluster_data = self._create_cluster_data(cluster_id, cluster_places)\n",
    "            clustered_results.append(cluster_data)\n",
    "\n",
    "        # Sort clusters by priority (central first)\n",
    "        clustered_results.sort(key=lambda x: self.cluster_mapping.get(x['cluster_id'], {}).get('priority', 999))\n",
    "\n",
    "        return {\n",
    "            \"reasoning\": places_data.get('reasoning'),\n",
    "            \"places_found\": places_data.get('places_found', len(places)),\n",
    "            \"total_clusters\": len(clustered_results),\n",
    "            \"accommodation\": {\n",
    "                \"location\": accommodation_location,\n",
    "                \"geo_cluster_id\": self._calculate_geo_cluster_for_coords(\n",
    "                    accommodation_location.get('lat'),\n",
    "                    accommodation_location.get('lng') or accommodation_location.get('lon')\n",
    "                )\n",
    "            },\n",
    "            \"clustered_places\": clustered_results\n",
    "        }\n",
    "\n",
    "    def _group_by_geo_cluster(self, places: List[Dict]) -> Dict[str, List[Dict]]:\n",
    "        \"\"\"Group places by their geo_cluster_id.\"\"\"\n",
    "        clusters = {}\n",
    "        for place in places:\n",
    "            cluster_id = place.get('geo_cluster_id', 'unknown')\n",
    "            if cluster_id not in clusters:\n",
    "                clusters[cluster_id] = []\n",
    "            clusters[cluster_id].append(place)\n",
    "        return clusters\n",
    "\n",
    "    def _create_cluster_data(self, cluster_id: str, places: List[Dict]) -> Dict:\n",
    "        \"\"\"Create cluster data with travel connections.\"\"\"\n",
    "        cluster_info = self.cluster_mapping.get(cluster_id, {\"name\": f\"Unknown Cluster ({cluster_id})\", \"priority\": 999})\n",
    "\n",
    "        # Calculate travel connections for each place\n",
    "        places_with_travel = []\n",
    "        for place in places:\n",
    "            place_with_travel = place.copy()\n",
    "            travel_info = self._calculate_travel_to_place(place)\n",
    "            place_with_travel['travel_from_accommodation'] = travel_info\n",
    "            places_with_travel.append(place_with_travel)\n",
    "\n",
    "        # Sort places within cluster by distance from accommodation\n",
    "        places_with_travel.sort(key=lambda x: x['travel_from_accommodation']['distance_km'])\n",
    "\n",
    "        return {\n",
    "            \"cluster_id\": cluster_id,\n",
    "            \"cluster_name\": cluster_info[\"name\"],\n",
    "            \"places_count\": len(places_with_travel),\n",
    "            \"average_distance_km\": round(sum(p['travel_from_accommodation']['distance_km'] for p in places_with_travel) / len(places_with_travel), 2),\n",
    "            \"recommended_travel_mode\": self._get_cluster_recommended_mode(places_with_travel),\n",
    "            \"places\": places_with_travel\n",
    "        }\n",
    "\n",
    "    def _calculate_travel_to_place(self, place: Dict) -> Dict:\n",
    "        \"\"\"Calculate travel information from accommodation to place.\"\"\"\n",
    "        place_geo = place.get('geo', {})\n",
    "        place_lat = place_geo.get('latitude')\n",
    "        place_lng = place_geo.get('longitude')\n",
    "\n",
    "        if not place_lat or not place_lng or not self.accommodation_location:\n",
    "            return self._create_default_travel_info()\n",
    "\n",
    "        # Calculate distance using Haversine formula\n",
    "        # Handle both 'lng' and 'lon' formats for accommodation location\n",
    "        acc_lng = self.accommodation_location.get('lng') or self.accommodation_location.get('lon')\n",
    "        distance_km = self._haversine_distance(\n",
    "            self.accommodation_location.get('lat'),\n",
    "            acc_lng,\n",
    "            place_lat,\n",
    "            place_lng\n",
    "        )\n",
    "\n",
    "        # Determine travel modes and times\n",
    "        travel_modes = self._calculate_travel_modes(distance_km)\n",
    "\n",
    "        return {\n",
    "            \"distance_km\": round(distance_km, 2),\n",
    "            \"travel_modes\": travel_modes,\n",
    "            \"recommended_mode\": self._get_recommended_mode(distance_km)\n",
    "        }\n",
    "\n",
    "    def _haversine_distance(self, lat1: float, lng1: float, lat2: float, lng2: float) -> float:\n",
    "        \"\"\"Calculate distance between two points using Haversine formula.\"\"\"\n",
    "        # Convert to radians\n",
    "        lat1, lng1, lat2, lng2 = map(math.radians, [lat1, lng1, lat2, lng2])\n",
    "\n",
    "        # Haversine formula\n",
    "        dlat = lat2 - lat1\n",
    "        dlng = lng2 - lng1\n",
    "        a = math.sin(dlat/2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlng/2)**2\n",
    "        c = 2 * math.asin(math.sqrt(a))\n",
    "\n",
    "        # Earth radius in kilometers\n",
    "        earth_radius_km = 6371\n",
    "        return earth_radius_km * c\n",
    "\n",
    "    def _get_cluster_recommended_mode(self, places: List[Dict]) -> str:\n",
    "        \"\"\"Get recommended mode for entire cluster based on distances.\"\"\"\n",
    "        if not places:\n",
    "            return \"MRT\"\n",
    "\n",
    "        avg_distance = sum(p['travel_from_accommodation']['distance_km'] for p in places) / len(places)\n",
    "        return self._get_recommended_mode(avg_distance)\n",
    "\n",
    "    def _calculate_geo_cluster_for_coords(self, lat: float, lng: float) -> str:\n",
    "        \"\"\"Calculate geo cluster for given coordinates.\"\"\"\n",
    "        if not lat or not lng:\n",
    "            return \"unknown\"\n",
    "\n",
    "        # Singapore bounds check\n",
    "        if not (1.1 <= lat <= 1.5 and 103.6 <= lng <= 104.1):\n",
    "            return \"unknown\"\n",
    "\n",
    "        # Cluster logic for Singapore\n",
    "        if 1.25 <= lat <= 1.35 and 103.7 <= lng <= 103.9:\n",
    "            return \"central\"\n",
    "        elif lat > 1.35:\n",
    "            return \"north\"\n",
    "        elif lat < 1.35:\n",
    "            return \"south\"\n",
    "        elif lng > 103.8:\n",
    "            return \"east\"\n",
    "        else:\n",
    "            return \"west\"\n",
    "\n",
    "    def _create_empty_clusters_response(self, places_data: Dict) -> Dict:\n",
    "        \"\"\"Create response when no places to cluster.\"\"\"\n",
    "        return {\n",
    "            \"reasoning\": places_data.get('reasoning'),\n",
    "            \"places_found\": 0,\n",
    "            \"total_clusters\": 0,\n",
    "            \"accommodation\": {\n",
    "                \"location\": self.accommodation_location,\n",
    "                \"geo_cluster_id\": \"unknown\"\n",
    "            },\n",
    "            \"clustered_places\": []\n",
    "        }\n",
    "\n",
    "def run_agentic_workflow(input_data):\n",
    "    \"\"\"Run agent workflow: coordinate between reasoning, formatting, and clustering agents.\"\"\"\n",
    "\n",
    "    # Initialize agents\n",
    "    reasoning_agent = PlacesResearchReasoningAgent()\n",
    "    formatting_agent = PlacesResearchFormattingAgent()\n",
    "    clustering_agent = PlacesClusteringAgent()\n",
    "\n",
    "    # Create prompt for reasoning agent with input data\n",
    "    prompt = f\"\"\"\n",
    "    I need to find attractions for a trip to Singapore with the following requirements:\n",
    "\n",
    "    Trip Details:\n",
    "    - Duration: {input_data.get('duration_days', 1)} days\n",
    "    - Pace: {input_data.get('pace', 'moderate')}\n",
    "    - Budget: ${input_data.get('budget', 0)}\n",
    "\n",
    "    Optional Preferences:\n",
    "    - Interests: {input_data.get('optional', {}).get('interests', [])}\n",
    "    - Accommodation Location: {input_data.get('optional', {}).get('accommodation_location', {})}\n",
    "\n",
    "    Please search for appropriate attractions near the accommodation location based on these preferences.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get raw data from reasoning agent\n",
    "    reasoning_result = reasoning_agent(prompt)\n",
    "\n",
    "    # Format the results using formatting agent\n",
    "    formatted_result = formatting_agent.format_response(reasoning_result)\n",
    "\n",
    "    # Get accommodation location for clustering\n",
    "    accommodation_location = input_data.get('optional', {}).get('accommodation_location', {})\n",
    "\n",
    "    # Cluster the places geographically with travel connections\n",
    "    clustered_result = clustering_agent.cluster_places(formatted_result, accommodation_location)\n",
    "\n",
    "    return clustered_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cehvv6tzio9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agentic_workflow(input_data):\n",
    "    \"\"\"Run agent workflow: coordinate between reasoning and formatting agents.\"\"\"\n",
    "    \n",
    "    # Initialize agents\n",
    "    reasoning_agent = PlacesResearchReasoningAgent()\n",
    "    formatting_agent = PlacesResearchFormattingAgent()\n",
    "    cluster_agent = PlacesClusteringAgent()\n",
    "    \n",
    "    # Create prompt for reasoning agent with input data\n",
    "    prompt = f\"\"\"\n",
    "    I need to find attractions for a trip to Singapore with the following requirements:\n",
    "    \n",
    "    Trip Details:\n",
    "    - Duration: {input_data.get('duration_days', 1)} days\n",
    "    - Pace: {input_data.get('pace', 'moderate')}\n",
    "    - Budget: ${input_data.get('budget', 0)}\n",
    "    \n",
    "    Optional Preferences:\n",
    "    - Interests: {input_data.get('optional', {}).get('interests', [])}\n",
    "    - Accommodation Location: {input_data.get('optional', {}).get('accommodation_location', {})}\n",
    "    \n",
    "    Please search for appropriate attractions near the accommodation location based on these preferences.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get raw data from reasoning agent\n",
    "    reasoning_result = reasoning_agent(prompt)\n",
    "    \n",
    "    # Format the results using formatting agent\n",
    "    formatted_result = formatting_agent.format_response(reasoning_result)\n",
    "    \n",
    "    return formatted_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-27 15:42:16,948 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-27 15:42:16,962 - googlemaps.client - INFO - API queries_quota: 60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REASONING AGENT: Executing search_places with args: {'location': {'lat': 1.3294, 'lng': 103.8021}, 'keyword': 'park', 'radius': 5000, 'min_rating': 4.0}\n",
      "Fetching page 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-27 15:42:17,771 - googlemaps.client - INFO - API queries_quota: 60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REASONING AGENT: Executing search_places with args: {'location': {'lat': 1.3294, 'lng': 103.8021}, 'keyword': 'food', 'radius': 5000, 'min_rating': 4.2}\n",
      "Fetching page 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-27 15:42:18,553 - __main__ - INFO - Processing 37 raw places for formatting\n",
      "2025-09-27 15:42:18,553 - __main__ - INFO - Processing Wikipedia batch 1 with 10 places\n",
      "2025-09-27 15:42:20,272 - __main__ - INFO - Found Wikipedia info for: Fort Canning Park\n",
      "2025-09-27 15:42:22,020 - __main__ - INFO - Found Wikipedia info for: Bukit Batok Nature Park\n",
      "2025-09-27 15:42:23,726 - __main__ - INFO - Found Wikipedia info for: Bishan-Ang Mo Kio Park\n",
      "2025-09-27 15:42:25,514 - __main__ - INFO - Found Wikipedia info for: National Parks Board\n",
      "2025-09-27 15:42:27,203 - __main__ - INFO - Found Wikipedia info for: Istana Park\n",
      "2025-09-27 15:42:28,939 - __main__ - INFO - Found Wikipedia info for: Mount Emily Park\n",
      "2025-09-27 15:42:30,547 - __main__ - INFO - Found Wikipedia info for: Petir Park\n",
      "2025-09-27 15:42:32,248 - __main__ - INFO - Found Wikipedia info for: Lower Peirce Reservoir Park\n",
      "2025-09-27 15:42:33,909 - __main__ - INFO - Found Wikipedia info for: Kim Seng Park\n",
      "2025-09-27 15:42:34,633 - __main__ - INFO - Found Wikipedia info for: Ang Mo Kio Town Garden West\n",
      "2025-09-27 15:42:56,318 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-27 15:42:56,321 - __main__ - INFO - LLM response (first 100 chars): [\n",
      "  {\n",
      "    \"description\": \"Fort Canning Park is a historic hilltop park in Singapore's central busine...\n",
      "2025-09-27 15:42:56,322 - __main__ - INFO - Successfully enriched batch 1\n",
      "2025-09-27 15:42:56,323 - __main__ - INFO - Processing Wikipedia batch 2 with 10 places\n",
      "2025-09-27 15:42:58,840 - __main__ - INFO - Found Wikipedia info for: Pearl's Hill City Park\n",
      "2025-09-27 15:43:00,660 - __main__ - INFO - Found Wikipedia info for: West Coast Park\n",
      "2025-09-27 15:43:02,365 - __main__ - INFO - Found Wikipedia info for: Chestnut Nature Park\n",
      "2025-09-27 15:43:04,049 - __main__ - INFO - Found Wikipedia info for: TreeTop Walk\n",
      "C:\\Users\\weiwe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file C:\\Users\\weiwe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n",
      "2025-09-27 15:43:05,881 - __main__ - INFO - Found Wikipedia info for: Jubilee Park\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia search error: \"Jubilee Park\" may refer to: \n",
      "Jubilee Park, Mackay\n",
      "Jubilee Park, Melbourne\n",
      "Jubelpark\n",
      "Woodhall Spa\n",
      "Canary Wharf tube station\n",
      "park in the London Borough of Enfield\n",
      "Leyton Jubilee Park\n",
      "Jubilee Park, Jamshedpur\n",
      "Normandale, New Zealand\n",
      "Glynn\n",
      "Fort Canning Park\n",
      "Jubilee Park, Dallas\n",
      "Sultan Haji Hassanal Bolkiah Silver Jubilee Park\n",
      "Jubilee Parkway\n",
      "All pages with titles containing Jubilee Park\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-27 15:43:07,615 - __main__ - INFO - Found Wikipedia info for: Bukit Timah Nature Reserve\n",
      "2025-09-27 15:43:09,280 - __main__ - INFO - Found Wikipedia info for: Learning Forest\n",
      "2025-09-27 15:43:10,989 - __main__ - INFO - Found Wikipedia info for: MacRitchie Reservoir Park\n",
      "2025-09-27 15:43:12,614 - __main__ - INFO - Found Wikipedia info for: Bishan Active Park\n",
      "2025-09-27 15:43:14,315 - __main__ - INFO - Found Wikipedia info for: Upper Peirce Reservoir Park\n",
      "2025-09-27 15:43:37,914 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-27 15:43:37,915 - __main__ - INFO - LLM response (first 100 chars): [\n",
      "  {\n",
      "    \"description\": \"Pearl's Hill City Park is a serene 9-hectare oasis built around a reservoi...\n",
      "2025-09-27 15:43:37,915 - __main__ - INFO - Successfully enriched batch 2\n",
      "2025-09-27 15:43:37,916 - __main__ - INFO - Processing Wikipedia batch 3 with 10 places\n",
      "2025-09-27 15:43:39,579 - __main__ - INFO - Found Wikipedia info for: Little Lazy Lizard\n",
      "2025-09-27 15:43:41,338 - __main__ - INFO - Found Wikipedia info for: Tha Siam Thai Kitchen\n",
      "2025-09-27 15:43:43,127 - __main__ - INFO - Found Wikipedia info for: Asian Twist by 365 Food\n",
      "2025-09-27 15:43:43,796 - __main__ - INFO - Found Wikipedia info for: San Ren Xing 三人行 - Thomson Plaza\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\logging\\__init__.py\", line 1163, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\encodings\\cp1252.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "UnicodeEncodeError: 'charmap' codec can't encode characters in position 83-85: character maps to <undefined>\n",
      "Call stack:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\weiwe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\weiwe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\weiwe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\weiwe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 645, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 1999, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\weiwe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 519, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\weiwe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 508, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\weiwe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 400, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\weiwe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 368, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\weiwe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\weiwe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 455, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\weiwe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 577, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\weiwe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\weiwe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\weiwe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\weiwe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\weiwe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\weiwe\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\weiwe\\AppData\\Local\\Temp\\ipykernel_45284\\2305950662.py\", line 5, in <module>\n",
      "    result = run_agentic_workflow(input_data)\n",
      "  File \"C:\\Users\\weiwe\\AppData\\Local\\Temp\\ipykernel_45284\\1220286917.py\", line 29, in run_agentic_workflow\n",
      "    formatted_result = formatting_agent.format_response(reasoning_result)\n",
      "  File \"C:\\Users\\weiwe\\AppData\\Local\\Temp\\ipykernel_45284\\2501024234.py\", line 72, in format_response\n",
      "    formatted_places = self.format_places(raw_places, {})\n",
      "  File \"C:\\Users\\weiwe\\AppData\\Local\\Temp\\ipykernel_45284\\2501024234.py\", line 119, in format_places\n",
      "    formatted_places = self._generate_wikipedia_descriptions(formatted_places)\n",
      "  File \"C:\\Users\\weiwe\\AppData\\Local\\Temp\\ipykernel_45284\\2501024234.py\", line 249, in _generate_wikipedia_descriptions\n",
      "    logger.info(f\"Found Wikipedia info for: {place['name']}\")\n",
      "Message: 'Found Wikipedia info for: San Ren Xing 三人行 - Thomson Plaza'\n",
      "Arguments: ()\n",
      "2025-09-27 15:43:45,759 - __main__ - INFO - Found Wikipedia info for: Ang Mo Kio Central Market & Food Centre\n",
      "2025-09-27 15:43:47,520 - __main__ - INFO - Found Wikipedia info for: Bonding Kitchen Orchard Singapore\n",
      "2025-09-27 15:43:49,820 - __main__ - INFO - Found Wikipedia info for: Food Exchange\n",
      "2025-09-27 15:43:51,606 - __main__ - INFO - Found Wikipedia info for: Guzman y Gomez - Orchard Gateway\n",
      "2025-09-27 15:43:53,528 - __main__ - INFO - Found Wikipedia info for: Redhill Food Centre\n",
      "2025-09-27 15:43:55,535 - __main__ - INFO - Found Wikipedia info for: Peach Garden @ Chinatown Point\n",
      "2025-09-27 15:44:17,048 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-27 15:44:17,052 - __main__ - INFO - LLM response (first 100 chars): [\n",
      "  {\n",
      "    \"description\": \"Little Lazy Lizard offers a delightful dining experience in Bukit Timah, w...\n",
      "2025-09-27 15:44:17,052 - __main__ - INFO - Successfully enriched batch 3\n",
      "2025-09-27 15:44:17,053 - __main__ - INFO - Processing Wikipedia batch 4 with 7 places\n",
      "2025-09-27 15:44:18,724 - __main__ - INFO - Found Wikipedia info for: Siri House Dempsey\n",
      "2025-09-27 15:44:20,493 - __main__ - INFO - Found Wikipedia info for: Newton Food Centre\n",
      "2025-09-27 15:44:22,275 - __main__ - INFO - Found Wikipedia info for: Artichoke\n",
      "2025-09-27 15:44:24,114 - __main__ - INFO - Found Wikipedia info for: ABC Brickworks Market & Food Centre\n",
      "2025-09-27 15:44:26,193 - __main__ - INFO - Found Wikipedia info for: Ayer Rajah Food Centre\n",
      "2025-09-27 15:44:26,790 - __main__ - INFO - Found Wikipedia info for: Vibez Bistro Bar\n",
      "2025-09-27 15:44:28,650 - __main__ - INFO - Found Wikipedia info for: Alexandra Village Food Centre\n",
      "2025-09-27 15:44:35,324 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-09-27 15:44:35,329 - __main__ - INFO - LLM response (first 100 chars): [\n",
      "  {\n",
      "    \"description\": \"Siri House Dempsey offers a unique dining experience in the lush surroundi...\n",
      "2025-09-27 15:44:35,329 - __main__ - INFO - Successfully enriched batch 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results written to output.json\n"
     ]
    }
   ],
   "source": [
    "# Load input data\n",
    "input_file = '../inputs/garden_only_input.json'\n",
    "input_data = load_input_file(input_file)\n",
    "\n",
    "result = run_agentic_workflow(input_data)\n",
    "\n",
    "with open('output.json', 'w') as f:\n",
    "    json.dump(result, f, indent=2)\n",
    "\n",
    "print(\"Results written to output.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
